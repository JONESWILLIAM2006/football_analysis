"""
RTSP Stream Ingester
Multi-camera sync with timecode, frame hash, and audio fingerprinting
"""

import cv2
import numpy as np
import threading
import queue
import time
import json
import hashlib
from typing import Dict, List, Tuple, Optional
import redis
from scipy.signal import correlate
import librosa
import asyncio
import logging
from dataclasses import dataclass
from datetime import datetime

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class StreamInfo:
    stream_id: str
    url: str
    name: str
    fps: float
    resolution: Tuple[int, int]
    status: str = "active"

class RTSPIngester:
    """Multi-camera RTSP stream ingester with synchronization"""
    
    def __init__(self, redis_host: str = "redis", redis_port: int = 6379):
        self.redis_client = redis.Redis(host=redis_host, port=redis_port, db=0)
        self.streams: Dict[str, StreamInfo] = {}
        self.capture_threads: Dict[str, threading.Thread] = {}
        self.frame_buffers: Dict[str, queue.Queue] = {}
        self.timestamp_buffers: Dict[str, queue.Queue] = {}
        self.audio_fingerprints: Dict[str, np.ndarray] = {}
        self.sync_offsets: Dict[str, float] = {}
        self.running = False
        
    def add_stream(self, stream_id: str, rtsp_url: str, stream_name: str = "Unknown"):
        """Add RTSP stream for ingestion"""
        try:\n            # Test connection\n            cap = cv2.VideoCapture(rtsp_url)\n            if not cap.isOpened():\n                raise ValueError(f"Cannot connect to RTSP stream: {rtsp_url}")\n            \n            # Get stream properties\n            fps = cap.get(cv2.CAP_PROP_FPS)\n            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n            \n            cap.release()\n            \n            # Create stream info\n            stream_info = StreamInfo(\n                stream_id=stream_id,\n                url=rtsp_url,\n                name=stream_name,\n                fps=fps,\n                resolution=(width, height)\n            )\n            \n            self.streams[stream_id] = stream_info\n            self.frame_buffers[stream_id] = queue.Queue(maxsize=30)\n            self.timestamp_buffers[stream_id] = queue.Queue(maxsize=30)\n            \n            logger.info(f"Added stream {stream_id}: {stream_name} ({width}x{height} @ {fps}fps)")\n            \n        except Exception as e:\n            logger.error(f"Failed to add stream {stream_id}: {e}")\n            raise\n    \n    def start_ingestion(self):\n        """Start ingesting all streams"""\n        self.running = True\n        \n        for stream_id in self.streams:\n            thread = threading.Thread(\n                target=self._capture_stream,\n                args=(stream_id,),\n                daemon=True\n            )\n            thread.start()\n            self.capture_threads[stream_id] = thread\n            \n        logger.info(f"Started ingestion for {len(self.streams)} streams")\n    \n    def stop_ingestion(self):\n        """Stop all stream ingestion"""\n        self.running = False\n        \n        # Wait for threads to finish\n        for thread in self.capture_threads.values():\n            thread.join(timeout=5)\n            \n        logger.info("Stopped all stream ingestion")\n    \n    def _capture_stream(self, stream_id: str):\n        """Capture frames from a single stream"""\n        stream_info = self.streams[stream_id]\n        cap = cv2.VideoCapture(stream_info.url)\n        \n        # Configure capture\n        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # Reduce buffer for real-time\n        cap.set(cv2.CAP_PROP_FPS, 30)\n        \n        frame_count = 0\n        last_fps_time = time.time()\n        \n        while self.running:\n            ret, frame = cap.read()\n            if not ret:\n                logger.warning(f"Failed to read frame from {stream_id}, reconnecting...")\n                cap.release()\n                time.sleep(1)\n                cap = cv2.VideoCapture(stream_info.url)\n                continue\n            \n            timestamp = time.time()\n            frame_count += 1\n            \n            # Add frame to buffer if not full\n            if not self.frame_buffers[stream_id].full():\n                self.frame_buffers[stream_id].put(frame)\n                self.timestamp_buffers[stream_id].put(timestamp)\n                \n                # Publish frame to Redis for real-time processing\n                self._publish_frame(stream_id, frame, timestamp)\n            \n            # Log FPS every 30 frames\n            if frame_count % 30 == 0:\n                current_time = time.time()\n                fps = 30 / (current_time - last_fps_time)\n                logger.debug(f"Stream {stream_id} FPS: {fps:.1f}")\n                last_fps_time = current_time\n        \n        cap.release()\n        logger.info(f"Stopped capturing stream {stream_id}")\n    \n    def _publish_frame(self, stream_id: str, frame: np.ndarray, timestamp: float):\n        """Publish frame to Redis for real-time processing"""\n        try:\n            # Encode frame\n            _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 80])\n            frame_data = {\n                'stream_id': stream_id,\n                'timestamp': timestamp,\n                'frame': buffer.tobytes().hex(),\n                'shape': frame.shape\n            }\n            \n            # Publish to Redis stream\n            self.redis_client.xadd(\n                f"stream:{stream_id}",\n                frame_data,\n                maxlen=100  # Keep only last 100 frames\n            )\n            \n        except Exception as e:\n            logger.error(f"Failed to publish frame for {stream_id}: {e}")\n    \n    def sync_streams_by_timecode(self) -> Dict[str, float]:\n        """Synchronize streams using embedded timecode"""\n        offsets = {}\n        \n        if len(self.streams) < 2:\n            return {stream_id: 0.0 for stream_id in self.streams}\n        \n        # Use first stream as reference\n        reference_stream = list(self.streams.keys())[0]\n        offsets[reference_stream] = 0.0\n        \n        # Calculate offsets for other streams\n        for stream_id in self.streams:\n            if stream_id == reference_stream:\n                continue\n                \n            offset = self._calculate_timecode_offset(reference_stream, stream_id)\n            offsets[stream_id] = offset\n            \n        self.sync_offsets = offsets\n        logger.info(f"Calculated sync offsets: {offsets}")\n        return offsets\n    \n    def sync_streams_by_frame_hash(self) -> Dict[str, float]:\n        """Synchronize streams using frame content hashing"""\n        offsets = {}\n        \n        if len(self.streams) < 2:\n            return {stream_id: 0.0 for stream_id in self.streams}\n        \n        # Get frame hashes for each stream\n        stream_hashes = {}\n        for stream_id in self.streams:\n            hashes = self._get_frame_hashes(stream_id, num_frames=60)  # 2 seconds at 30fps\n            stream_hashes[stream_id] = hashes\n        \n        # Find best alignment\n        reference_stream = list(self.streams.keys())[0]\n        offsets[reference_stream] = 0.0\n        \n        ref_hashes = stream_hashes[reference_stream]\n        \n        for stream_id in self.streams:\n            if stream_id == reference_stream:\n                continue\n                \n            stream_hashes_data = stream_hashes[stream_id]\n            offset = self._find_best_hash_alignment(ref_hashes, stream_hashes_data)\n            offsets[stream_id] = offset / 30.0  # Convert frames to seconds\n            \n        self.sync_offsets = offsets\n        logger.info(f"Frame hash sync offsets: {offsets}")\n        return offsets\n    \n    def sync_streams_by_audio(self) -> Dict[str, float]:\n        """Synchronize streams using audio fingerprinting"""\n        offsets = {}\n        \n        if len(self.streams) < 2:\n            return {stream_id: 0.0 for stream_id in self.streams}\n        \n        # Extract audio fingerprints\n        for stream_id in self.streams:\n            fingerprint = self._extract_audio_fingerprint(stream_id)\n            self.audio_fingerprints[stream_id] = fingerprint\n        \n        # Use first stream as reference\n        reference_stream = list(self.streams.keys())[0]\n        ref_fingerprint = self.audio_fingerprints[reference_stream]\n        offsets[reference_stream] = 0.0\n        \n        # Calculate cross-correlation offsets\n        for stream_id in self.streams:\n            if stream_id == reference_stream:\n                continue\n                \n            stream_fingerprint = self.audio_fingerprints[stream_id]\n            offset = self._calculate_audio_offset(ref_fingerprint, stream_fingerprint)\n            offsets[stream_id] = offset\n            \n        self.sync_offsets = offsets\n        logger.info(f"Audio sync offsets: {offsets}")\n        return offsets\n    \n    def _calculate_timecode_offset(self, ref_stream: str, target_stream: str) -> float:\n        """Calculate offset between streams using timecode"""\n        # Simplified timecode extraction (would need actual timecode parsing)\n        # For now, return 0 as placeholder\n        return 0.0\n    \n    def _get_frame_hashes(self, stream_id: str, num_frames: int = 60) -> List[str]:\n        """Get frame hashes for synchronization"""\n        hashes = []\n        frame_buffer = self.frame_buffers[stream_id]\n        \n        # Get frames from buffer\n        frames = []\n        temp_frames = []\n        \n        # Extract available frames\n        while not frame_buffer.empty() and len(frames) < num_frames:\n            frame = frame_buffer.get()\n            frames.append(frame)\n            temp_frames.append(frame)\n        \n        # Put frames back\n        for frame in temp_frames:\n            if not frame_buffer.full():\n                frame_buffer.put(frame)\n        \n        # Calculate hashes\n        for frame in frames:\n            # Convert to grayscale and resize for consistent hashing\n            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n            resized = cv2.resize(gray, (64, 64))\n            \n            # Calculate hash\n            frame_hash = hashlib.md5(resized.tobytes()).hexdigest()\n            hashes.append(frame_hash)\n        \n        return hashes\n    \n    def _find_best_hash_alignment(self, ref_hashes: List[str], target_hashes: List[str]) -> int:\n        """Find best alignment between hash sequences"""\n        if not ref_hashes or not target_hashes:\n            return 0\n        \n        best_offset = 0\n        best_score = 0\n        \n        # Try different offsets\n        max_offset = min(len(ref_hashes), len(target_hashes)) // 2\n        \n        for offset in range(-max_offset, max_offset + 1):\n            score = 0\n            comparisons = 0\n            \n            for i in range(len(ref_hashes)):\n                target_idx = i + offset\n                if 0 <= target_idx < len(target_hashes):\n                    if ref_hashes[i] == target_hashes[target_idx]:\n                        score += 1\n                    comparisons += 1\n            \n            if comparisons > 0:\n                normalized_score = score / comparisons\n                if normalized_score > best_score:\n                    best_score = normalized_score\n                    best_offset = offset\n        \n        return best_offset\n    \n    def _extract_audio_fingerprint(self, stream_id: str) -> np.ndarray:\n        """Extract audio fingerprint for synchronization"""\n        # Simplified audio extraction (would need actual audio processing)\n        # For now, return random fingerprint as placeholder\n        return np.random.random(1000)\n    \n    def _calculate_audio_offset(self, ref_audio: np.ndarray, target_audio: np.ndarray) -> float:\n        """Calculate time offset using audio cross-correlation"""\n        if len(ref_audio) == 0 or len(target_audio) == 0:\n            return 0.0\n            \n        # Cross-correlation\n        correlation = correlate(ref_audio, target_audio, mode='full')\n        offset_samples = np.argmax(correlation) - len(target_audio) + 1\n        \n        # Convert to seconds (assuming 44.1kHz sample rate)\n        return offset_samples / 44100.0\n    \n    def get_synced_frames(self) -> Dict[str, Tuple[np.ndarray, float]]:\n        """Get synchronized frames from all streams"""\n        synced_frames = {}\n        current_time = time.time()\n        \n        for stream_id in self.streams:\n            if stream_id in self.frame_buffers and not self.frame_buffers[stream_id].empty():\n                frame = self.frame_buffers[stream_id].get()\n                timestamp = self.timestamp_buffers[stream_id].get()\n                \n                # Apply sync offset\n                offset = self.sync_offsets.get(stream_id, 0.0)\n                adjusted_timestamp = timestamp + offset\n                \n                synced_frames[stream_id] = (frame, adjusted_timestamp)\n        \n        return synced_frames\n    \n    def get_stream_status(self) -> Dict[str, Dict]:\n        """Get status of all streams"""\n        status = {}\n        \n        for stream_id, stream_info in self.streams.items():\n            buffer_size = self.frame_buffers[stream_id].qsize()\n            \n            status[stream_id] = {\n                'name': stream_info.name,\n                'url': stream_info.url,\n                'fps': stream_info.fps,\n                'resolution': stream_info.resolution,\n                'buffer_size': buffer_size,\n                'status': stream_info.status,\n                'sync_offset': self.sync_offsets.get(stream_id, 0.0)\n            }\n        \n        return status\n\nclass RTSPIngestService:\n    """Service wrapper for RTSP ingestion"""\n    \n    def __init__(self):\n        self.ingester = RTSPIngester()\n        self.redis_client = redis.Redis(host='redis', port=6379, db=0)\n        \n    async def start_service(self):\n        """Start the RTSP ingestion service"""\n        logger.info("Starting RTSP Ingestion Service")\n        \n        # Load streams from Redis\n        await self._load_streams_from_redis()\n        \n        # Start ingestion\n        self.ingester.start_ingestion()\n        \n        # Start sync monitoring\n        asyncio.create_task(self._monitor_sync())\n        \n        logger.info("RTSP Ingestion Service started")\n    \n    async def _load_streams_from_redis(self):\n        """Load stream configurations from Redis"""\n        try:\n            # Get streams from Redis list\n            while True:\n                stream_data = self.redis_client.brpop("rtsp_streams", timeout=1)\n                if not stream_data:\n                    break\n                    \n                stream_info = json.loads(stream_data[1])\n                \n                self.ingester.add_stream(\n                    stream_info['stream_id'],\n                    stream_info['url'],\n                    stream_info['name']\n                )\n                \n        except Exception as e:\n            logger.error(f"Failed to load streams from Redis: {e}")\n    \n    async def _monitor_sync(self):\n        """Monitor and maintain stream synchronization"""\n        while True:\n            try:\n                # Re-sync every 30 seconds\n                await asyncio.sleep(30)\n                \n                if len(self.ingester.streams) > 1:\n                    # Try different sync methods\n                    logger.info("Re-synchronizing streams...")\n                    \n                    # Try frame hash sync first\n                    offsets = self.ingester.sync_streams_by_frame_hash()\n                    \n                    # Fallback to audio sync if available\n                    if all(offset == 0 for offset in offsets.values()):\n                        offsets = self.ingester.sync_streams_by_audio()\n                    \n                    logger.info(f"Updated sync offsets: {offsets}")\n                    \n            except Exception as e:\n                logger.error(f"Sync monitoring error: {e}")\n\nasync def main():\n    """Main entry point"""\n    service = RTSPIngestService()\n    \n    try:\n        await service.start_service()\n        \n        # Keep service running\n        while True:\n            await asyncio.sleep(1)\n            \n    except KeyboardInterrupt:\n        logger.info("Shutting down RTSP Ingestion Service")\n        service.ingester.stop_ingestion()\n\nif __name__ == "__main__":\n    asyncio.run(main())